{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the analysis pipeline remotely (beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before executing the pipeline, check whether all config file are set according to your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigate to the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../pipeline')\n",
    "sys.path.append('./')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the environment\n",
    "When running this notebook for the first time in your jupyter hub session, first the dependencies of the pipeline scripts need to be installed. When this is not the first execution of the notebook, this step can be skipped.\n",
    "\n",
    "The package requirements are specified in the `requirements.txt` file and can be installed with the magic `%pip` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this method may not always be reliable. Thus, it is here better to install each package explicitly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install snakemake==5.9.1\n",
    "%pip install jinja2==2.10.3\n",
    "%pip install pygments==2.4.2\n",
    "%pip install pygraphviz==1.5\n",
    "%pip install git+git://github.com/NeuralEnsemble/elephant.git #(pip install from git repo branch)\n",
    "%pip install git+https://github.com/G-Node/python-neo.git@fix/nixio-read-channel-names\n",
    "%pip install nixio==1.5.0b4\n",
    "%pip install pillow==6.2.1\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install networkx\n",
    "%pip install shapely==1.6.4.post2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update the kernel with the newly installed packages, the kernel needs to restartet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set output location\n",
    "Here, you can specify where the output files of the pipelines should be stored.\n",
    "The suggested location would be your personal drive storage:\n",
    "\n",
    "`/mnt/uset/drive/My Library/Slow Wave Analysis Pipeline/results/<dataset>/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Content:\n",
      " output_path = '/mnt/user/drive/My Libraries/Slow Wave Analysis Pipeline/results/IDIBAPS' \n",
      "\n",
      " New Content:\n",
      " output_path = '/mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/results/IDIBAPS'\n"
     ]
    }
   ],
   "source": [
    "def update_output_path(path):\n",
    "    with open('settings.py', 'r') as f:\n",
    "        prev_content = f.read()\n",
    "    with open('settings.py', 'w') as f:\n",
    "        f.write(\"output_path = '{}'\".format(path))\n",
    "    print(\"Previous Content:\\n\", prev_content, \"\\n\\n\",\n",
    "          \"New Content:\\n\", \"output_path = '{}'\".format(path))\n",
    "    return None\n",
    "    \n",
    "update_output_path('/mnt/user/drive/My Library/Slow Wave Analysis Pipeline/results/IDIBAPS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) navigate to a specific stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('stage02_preprocessing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mExecuting subworkflow stage01.\u001b[0m\n",
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mUsing shell: /usr/bin/bash\u001b[0m\n",
      "\u001b[33mProvided cores: 1 (use --cores to define parallelism)\u001b[0m\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tall\n",
      "\t1\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 10 16:14:04 2020]\u001b[0m\n",
      "\u001b[32mrule all:\n",
      "    input: /mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/results/IDIBAPS/stage01_data_curation/output_IDIBAPS_161101_rec07_RH.nix\n",
      "    output: /mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/results/IDIBAPS/stage01_data_curation/IDIBAPS_data.nix\n",
      "    jobid: 0\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 10 16:14:11 2020]\u001b[0m\n",
      "\u001b[32mFinished job 0.\u001b[0m\n",
      "\u001b[32m1 of 1 steps (100%) done\u001b[0m\n",
      "\u001b[33mComplete log: /mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/pipeline/pipeline/stage01_data_curation/.snakemake/log/2020-01-10T161401.766641.snakemake.log\u001b[0m\n",
      "\u001b[33mExecuting subworkflow stage02.\u001b[0m\n",
      "\u001b[33mBuilding DAG of jobs...\u001b[0m\n",
      "\u001b[33mUsing shell: /usr/bin/bash\u001b[0m\n",
      "\u001b[33mProvided cores: 1 (use --cores to define parallelism)\u001b[0m\n",
      "\u001b[33mRules claiming more threads will be scaled down.\u001b[0m\n",
      "\u001b[33mJob counts:\n",
      "\tcount\tjobs\n",
      "\t1\tall\n",
      "\t1\tbackground_substraction\n",
      "\t1\tclear\n",
      "\t1\tnormalization\n",
      "\t1\troi_selection\n",
      "\t5\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 10 16:14:11 2020]\u001b[0m\n",
      "\u001b[32mrule clear:\n",
      "    output: /mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/results/IDIBAPS/stage02_preprocessing/clear.done\n",
      "    jobid: 2\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 10 16:14:11 2020]\u001b[0m\n",
      "\u001b[32mFinished job 2.\u001b[0m\n",
      "\u001b[32m1 of 5 steps (20%) done\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32m[Fri Jan 10 16:14:11 2020]\u001b[0m\n",
      "\u001b[32mrule roi_selection:\n",
      "    input: /mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/results/IDIBAPS/stage02_preprocessing/clear.done, /mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/results/IDIBAPS/stage01_data_curation/IDIBAPS_data.nix, scripts/roi_selection.py\n",
      "    output: /mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/results/IDIBAPS/stage02_preprocessing/roi_selection/roi_selection.nix, /mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/results/IDIBAPS/stage02_preprocessing/roi_selection/roi_selection.png\n",
      "    jobid: 4\n",
      "    wildcards: rule_name=roi_selection\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "/usr/bin/bash: line 1:  1884 Killed                  python scripts/roi_selection.py --data \"/mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/results/IDIBAPS/stage01_data_curation/IDIBAPS_data.nix\" --output \"/mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/results/IDIBAPS/stage02_preprocessing/roi_selection/roi_selection.nix\" --image_output \"/mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/results/IDIBAPS/stage02_preprocessing/roi_selection/roi_selection.png\" --intensity_threshold 0.5\n",
      "\u001b[32m[Fri Jan 10 16:14:22 2020]\u001b[0m\n",
      "\u001b[31mError in rule roi_selection:\u001b[0m\n",
      "\u001b[31m    jobid: 4\u001b[0m\n",
      "\u001b[31m    output: /mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/results/IDIBAPS/stage02_preprocessing/roi_selection/roi_selection.nix, /mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/results/IDIBAPS/stage02_preprocessing/roi_selection/roi_selection.png\u001b[0m\n",
      "\u001b[31m    shell:\n",
      "        \n",
      "        python scripts/roi_selection.py --data \"/mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/results/IDIBAPS/stage01_data_curation/IDIBAPS_data.nix\"                               --output \"/mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/results/IDIBAPS/stage02_preprocessing/roi_selection/roi_selection.nix\"                               --image_output \"/mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/results/IDIBAPS/stage02_preprocessing/roi_selection/roi_selection.png\"                               --intensity_threshold 0.5\n",
      "        \n",
      "        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)\u001b[0m\n",
      "\u001b[31m\u001b[0m\n",
      "\u001b[33mShutting down, this might take some time.\u001b[0m\n",
      "\u001b[31mExiting because a job execution failed. Look above for error message\u001b[0m\n",
      "\u001b[33mComplete log: /mnt/user/drive/Shared with groups/Slow Wave Analysis Pipeline/pipeline/pipeline/stage02_preprocessing/.snakemake/log/2020-01-10T161411.428946.snakemake.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('Working directory: ', os.getcwd())\n",
    "!snakemake"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
